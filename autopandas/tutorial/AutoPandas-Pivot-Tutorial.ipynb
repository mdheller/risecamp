{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## AutoPandas\n",
    "<img src=\"./imgs/autopandas-logo.png\" alt=\"AutoPandas Logo\" style=\"width: 10%; float: left; padding: 10px\"/>\n",
    "\n",
    "\n",
    "[AutoPandas](https://autopandas.io) is a input-output example based synthesis engine for the [Pandas](https://pandas.pydata.org) data-analytics library in Python. Users provide input-output pairs (dataframes) specifying their intent, and the AutoPandas engine searches for programs using the Pandas library that transform the input to the output.\n",
    "\n",
    "## Atlas\n",
    "\n",
    "[Atlas](https://github.com/rbavishi/atlas) is the framework instantiating AutoPandas. It generalizes the key ideas behind its synthesis engine making it possible to apply them to build engines for entirely new domains such as other APIs like Numpy or Tensorflow, or domain-specific languages (DSLs) for say string-manipulation.\n",
    "\n",
    "## What are we going to learn?\n",
    "\n",
    "Pandas is a huge library, and building a synthesizer for the entirety of Pandas is out-of-scope for the tutorial.\n",
    "Instead we will pick a single function in Pandas, namely `pivot`, and try to build an efficient synthesizer for it. That is, given input and output dataframes, our synthesizer will determine the right arguments to the `pivot` function.\n",
    "\n",
    "We will be using the the abstractions provided by Atlas and in doing so, we hope to motivate why we feel these abstractions are useful for instantiating engines for other domains.\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Synthesis Task\n",
    "\n",
    "The user provides input dataframe(s) as well as an output dataframe. Our system should be able to produce a call or a sequence of calls using `pivot`, `groupby` and various aggregation functions that transform the input to the desired output. Here's an example - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foo</th>\n",
       "      <th>bar</th>\n",
       "      <th>baz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two</td>\n",
       "      <td>A</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two</td>\n",
       "      <td>B</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>two</td>\n",
       "      <td>C</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   foo bar  baz\n",
       "0  one   A   10\n",
       "1  one   B   20\n",
       "2  one   C   30\n",
       "3  two   A   40\n",
       "4  two   B   50\n",
       "5  two   C   60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A   B   C\n",
       "one  10  20  30\n",
       "two  40  50  60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "inp_df = pd.DataFrame({\n",
    "  'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n",
    "  'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "  'baz': [10, 20, 30, 40, 50, 60],\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    'A': {'one': 10, 'two': 40},\n",
    "    'B': {'one': 20, 'two': 50},\n",
    "    'C': {'one': 30, 'two': 60}\n",
    "})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write a method `synthesize_pivot` that when run on the input-output example as follows -\n",
    "\n",
    "```python\n",
    "synthesize_pivot(inp_df, out_df)\n",
    "```\n",
    "\n",
    "returns the following program or an equivalent program\n",
    "\n",
    "```python\n",
    "inp_df.pivot(index=\"foo\", columns=\"bar\", values=\"baz\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A Brute-Force Synthesizer for Pivot\n",
    "\n",
    "Before we start building our synthesizer, we need to know the space of programs we are going to search over.\n",
    "\n",
    "### (a) What are the Possible Programs?\n",
    "\n",
    "Here's the documentation for pivot -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation for **Pivot**\n",
    "<img src=\"./imgs/pandas-pivot-doc.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information here! But here are the key points to help us get started -\n",
    "\n",
    "1. The `index` must be one of the columns of the input table or the value `None`.\n",
    "2. The `columns` argument must only be one of the columns and NOT `None`.\n",
    "3. The `values` argument must also be one of the columns or `None`. It can also be a list of columns.\n",
    "\n",
    "The set of possible arguments to `pivot` is therefore the cross-product of all the possible values for each of the arguments (`index`, `columns` and `pivot`) individually. How can we express this succintly? Now comes in the concept of a `generator` in Atlas/AutoPandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Introduction to Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple : ('foo', 'foo')\n",
      "Tuple : ('foo', 'bar')\n",
      "Tuple : ('foo', 'baz')\n",
      "Tuple : ('bar', 'foo')\n",
      "Tuple : ('bar', 'bar')\n",
      "Tuple : ('bar', 'baz')\n",
      "Tuple : ('baz', 'foo')\n",
      "Tuple : ('baz', 'bar')\n",
      "Tuple : ('baz', 'baz')\n"
     ]
    }
   ],
   "source": [
    "from atlas import generator\n",
    "\n",
    "@generator\n",
    "def gen_column_tuples(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Produces all possible 2-tuples of column names\n",
    "    \"\"\"\n",
    "    col1 = Select(df.columns)  # Select one of the columns\n",
    "    col2 = Select(df.columns)  # Select one of the columns\n",
    "    \n",
    "    return (col1, col2)  # Construct the tuple and return\n",
    "\n",
    "inp_df = pd.DataFrame({\n",
    "  'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n",
    "  'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "  'baz': [10, 20, 30, 40, 50, 60],\n",
    "})\n",
    "\n",
    "# Print all possible tuples that can be returned by gen_column_tuples\n",
    "# In this case all 3x3 = 9 tuples will be returned\n",
    "for result in gen_column_tuples.generate(inp_df):\n",
    "    print(\"Tuple :\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Select` operator is provided by Atlas. Given a list of values, it returns *one* of the values as the result. The `@generator` transforms any function into an Atlas Generator and overloads any calls to operators like `Select`. One can call `generate(*args, **kwargs)` on such a generator to get an iterator that returns the result of all possible executions of the generator (as governed by the calls to `Select`).\n",
    "\n",
    "By default, the iterator has **depth-first behavior**. That is, later calls to `Select` explore all possibilities before the previous `Select` calls.\n",
    "\n",
    "**NOTE** : An Atlas `generator` is different from the Python Generator. Everything that can be expressed using a python generator can be expressed as an Atlas generator. The power of Atlas generators is in combining these generators with probabilistic models as we will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) A Generator for Pivot Arguments\n",
    "\n",
    "At this point, you should have a fair idea of how to encode the constraints described in **2.(a)** using a generator. Let us try to write a generator for the arguments to the `pivot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns))\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + list(input_df.columns))\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]):\n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + list(input_df.columns))\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset(list(input_df.columns)))\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also ready to write the `synthesize_pivot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_equal(df1, df2):\n",
    "    try:\n",
    "        pd.testing.assert_frame_equal(df1, df2, check_names=False)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def synthesize_pivot(inp, out):\n",
    "    for args in gen_pivot_args.generate(inp):\n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on the example we had in **Section 1**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='foo', columns='bar', values='baz')\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "  'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n",
    "  'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "  'baz': [10, 20, 30, 40, 50, 60],\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    'A': {'one': 10, 'two': 40},\n",
    "    'B': {'one': 20, 'two': 50},\n",
    "    'C': {'one': 30, 'two': 60}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Analysis\n",
    "\n",
    "Let us log some statistics about our `synthesize_pivot` routine. In particular, let's track the number of programs explored, time taken and number of exceptions raised (while executing the program)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp):\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Explored Till Now: {num_explored}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue\n",
    "            \n",
    "    print(f\"Total Number of Programs Explored: {num_explored}\")\n",
    "    print(f\"Total Number of Programs Crashed: {num_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='foo', columns='bar', values='baz')\n",
      "Time to solution:  0.196 seconds\n",
      "Number of Programs Explored Till Now: 99\n",
      "Total Number of Programs Explored: 228\n",
      "Total Number of Programs Crashed: 57\n"
     ]
    }
   ],
   "source": [
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution was produced fairly quickly. But `57` of the `228` argument combinations returned by our generator `gen_pivot` errored out! This means our synthesizer is wasting time evaluating programs that do not even produce an output. Can we could optimize our synthesizer to avoid wasting time on these programs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Incorporating Domain-Specific Constraints in Generator\n",
    "\n",
    "Can we exploit our knowledge of the pivot function to avoid enumerating these programs? Turns out, a meaningful `pivot` program satisfies the following -\n",
    "\n",
    "1. `columns` and `index` argument cannot be equal\n",
    "2. The column(s) in `values` must be different from both `columns` and `index`.\n",
    "\n",
    "It is very easy to incorporate these constraints in the generator as it is regular Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns))\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in input_df.columns if i != arg_columns]) # CONSTRAINT-1\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]):\n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + [i for i in input_df.columns if i not in {arg_columns, arg_index}]) # CONSTRAINT-2\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset([i for i in input_df.columns if i not in {arg_columns, arg_index}])) # CONSTRAINT-2\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='foo', columns='bar', values='baz')\n",
      "Time to solution:  0.078 seconds\n",
      "Number of Programs Explored Till Now: 22\n",
      "Total Number of Programs Explored: 39\n",
      "Total Number of Programs Crashed: 0\n"
     ]
    }
   ],
   "source": [
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! We are getting to the solution much faster as we are not wasting time exploring bad programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Handling Big DataFrames\n",
    "\n",
    "We are still doing a brute-force search. Performance would suffer if the space of possible programs itself is pretty large. In the case of `pivot`, what happens if our dataframe has a large number of columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Expense</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>Terrace</td>\n",
       "      <td>9971.66</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>98.34</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>Pox</td>\n",
       "      <td>9726.03</td>\n",
       "      <td>Margaret</td>\n",
       "      <td>245.63</td>\n",
       "      <td>Lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Gate 320</td>\n",
       "      <td>9604.14</td>\n",
       "      <td>Helena</td>\n",
       "      <td>121.89</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Pox</td>\n",
       "      <td>9356.04</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>248.00</td>\n",
       "      <td>Lunch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Location  Balance   Added By  Expense Category\n",
       "0  2018-02-18   Terrace  9971.66    Theresa    98.34   Social\n",
       "1  2018-02-18       Pox  9726.03   Margaret   245.63    Lunch\n",
       "2  2018-02-24  Gate 320  9604.14     Helena   121.89   Social\n",
       "3  2018-02-24       Pox  9356.04  Katherine   248.00    Lunch"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lunch</th>\n",
       "      <th>Social</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-18</th>\n",
       "      <td>245.63</td>\n",
       "      <td>98.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-24</th>\n",
       "      <td>248.00</td>\n",
       "      <td>121.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lunch  Social\n",
       "2018-02-18  245.63   98.34\n",
       "2018-02-24  248.00  121.89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='Date', columns='Category', values='Expense')\n",
      "Time to solution:  7.823 seconds\n",
      "Number of Programs Explored Till Now: 3716\n",
      "Total Number of Programs Explored: 4056\n",
      "Total Number of Programs Crashed: 138\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'Date': {0: '2018-02-18', 1: '2018-02-18', 2: '2018-02-24', 3: '2018-02-24'},\n",
    "    'Location': {0: 'Terrace', 1: 'Pox', 2: 'Gate 320', 3: 'Pox'},\n",
    "    'Balance': {0: 9971.66, 1: 9726.03, 2: 9604.14, 3: 9356.04},\n",
    "    'Added By': {0: 'Theresa', 1: 'Margaret', 2: 'Helena', 3:'Katherine'},\n",
    "    'Expense': {0: 98.34, 1: 245.63, 2: 121.89, 3: 248.0},\n",
    "    'Category': {0: 'Social', 1: 'Lunch', 2: 'Social', 3: 'Lunch'}})\n",
    "\n",
    "out_df = pd.DataFrame({'Lunch': {'2018-02-18': 245.63, '2018-02-24': 248.0},\n",
    " 'Social': {'2018-02-18': 98.34, '2018-02-24': 121.89}})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! That is quite a bit slow. If we wanted to build a synthesis service where people can get their input-output queries answered in real-time, this approach would definitely not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a Generator\n",
    "\n",
    "The order of argument combinations returned by `gen_pivot` is governed by the order of values returned by the individual operators (four `Select`s and one `OrderedSubset`). Therefore, to speed up our synthesizer, the operators need to return the correct values *first*. \n",
    "\n",
    "#### Can we train the individual operators to return values **smartly** i.e. adjust the order in which they return values based on the input-output example?\n",
    "##### For the purpose of the tutorial, let's focus on the first call to `Select` i.e. the operator that decides the value of the `columns` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Adding Input-Output Example as the Context\n",
    "\n",
    "In order to train the operator, we first need to provide access to the input-output example. Currently only `inp_df` is passed as an argument to the generator `gen_pivot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame, output_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns), context=(input_df, output_df),  # ADDING CONTEXT HERE\n",
    "                         uid=\"select_columns\") # Adding uid to aid identification while defining model\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in input_df.columns if i != arg_columns])\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]):\n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + [i for i in input_df.columns if i not in {arg_columns, arg_index}])\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset([i for i in input_df.columns if i not in {arg_columns, arg_index}]))\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp, out):  # CHANGED : PASSING out AS AN ARGUMENT\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Explored Till Now: {num_explored}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue\n",
    "            \n",
    "    print(f\"Total Number of Programs Explored: {num_explored}\")\n",
    "    print(f\"Total Number of Programs Crashed: {num_errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Defining the Model\n",
    "\n",
    "We are going to use a Graph-Neural-Network model for our Select operator. Covering this model is out-of-scope for this tutorial, but here are the key insights behind using this model.\n",
    "\n",
    "1. The transformation represented by an input-output example consisting of dataframes is a function of the relationships between the values in the input and the values in the output, rather the concrete values themselves.  For example, the concrete column names `Category`, `Expense` etc. are irrelevant. It is their position in the output dataframe that really captures the transformation.\n",
    "\n",
    "2. We can represent dataframes as a graph where each column, cell and index value is represented as a node, and edges represent relationships amongst these nodes. The nodes are labeled with the type of the value (int, str etc.) rather than the value itself. For example, each column node will have a `COLUMN` edge to all the cell nodes in the corresponding column. We will also have an `EQUALITY` edge between between each pair of nodes that have the same concrete value.\n",
    "\n",
    "Here is a graphical representation of the graph encoding for the given input and output dataframe along with the domain for the `Select` operator we're trying to learn a model for."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/input-output-example.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>\n",
    "<img src=\"./imgs/graph-encoding-example.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the model for the generator. For more details, refer to the `models.py` file in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlas.models.imitation import IndependentOperatorsModel\n",
    "from atlas.operators import operator\n",
    "from models import PivotSelectModel\n",
    "\n",
    "class PivotGeneratorModel(IndependentOperatorsModel):\n",
    "    @operator(name='Select', uid=\"select_columns\")\n",
    "    def SelectColumns(*args, **kwargs):\n",
    "        config = {\n",
    "            'learning_rate': 0.01,\n",
    "            'node_dimension': 50,\n",
    "            'classifier_hidden_dims': [50],\n",
    "            'batch_size': 30000,  # number of nodes in a batch\n",
    "            'layer_timesteps': [1, 1, 1]\n",
    "        }\n",
    "\n",
    "        return PivotSelectModel(config, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training Data\n",
    "\n",
    "Training data for our purposes consists of **traces** of generator executions that produce the correct program given an input-output example. These traces store the correct choices made by the operators and hence are suffice as training data for the operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        GeneratorTrace(inputs=((      0           1     2       3                 4   5\n",
       "0   baz       123.4   baz  Joseph      banana_foo_2  50\n",
       "1   bar  23894243.7  fizz     Amy       date_bar_24  30\n",
       "2  buzz       123.4  buzz    Anne  cherimoya_baz_71  20\n",
       "3   foo       123.4  buzz  Nikita      apple_fizz_7  35,                             1                          2                      \\\n",
       "3                         Amy   Anne Joseph Nikita   Amy  Anne Joseph Nikita   \n",
       "4                                                                              \n",
       "apple_fizz_7              NaN    NaN    NaN  123.4   NaN   NaN    NaN   buzz   \n",
       "banana_foo_2              NaN    NaN  123.4    NaN   NaN   NaN    baz    NaN   \n",
       "cherimoya_baz_71          NaN  123.4    NaN    NaN   NaN  buzz    NaN    NaN   \n",
       "date_bar_24       2.38942e+07    NaN    NaN    NaN  fizz   NaN    NaN    NaN   \n",
       "\n",
       "                    5                     \n",
       "3                 Amy Anne Joseph Nikita  \n",
       "4                                         \n",
       "apple_fizz_7      NaN  NaN    NaN     35  \n",
       "banana_foo_2      NaN  NaN     50    NaN  \n",
       "cherimoya_baz_71  NaN   20    NaN    NaN  \n",
       "date_bar_24        30  NaN    NaN    NaN  ), {}),\n",
       "                       op_traces=[\n",
       "        OpTrace(op_info=OpInfo(sid='/gen_pivot_args/Select@select_columns@1', gen_name='gen_pivot_args', op_type='Select', index=1, gen_group=None, uid='select_columns', tags=None),\n",
       "                choice=3,\n",
       "                domain=[0, 1, 2, 3, 4, 5],\n",
       "                context=(      0           1     2       3                 4   5\n",
       "0   baz       123.4   baz  Joseph      banana_foo_2  50\n",
       "1   bar  23894243.7  fizz     Amy       date_bar_24  30\n",
       "2  buzz       123.4  buzz    Anne  cherimoya_baz_71  20\n",
       "3   foo       123.4  buzz  Nikita      apple_fizz_7  35,                             1                          2                      \\\n",
       "3                         Amy   Anne Joseph Nikita   Amy  Anne Joseph Nikita   \n",
       "4                                                                              \n",
       "apple_fizz_7              NaN    NaN    NaN  123.4   NaN   NaN    NaN   buzz   \n",
       "banana_foo_2              NaN    NaN  123.4    NaN   NaN   NaN    baz    NaN   \n",
       "cherimoya_baz_71          NaN  123.4    NaN    NaN   NaN  buzz    NaN    NaN   \n",
       "date_bar_24       2.38942e+07    NaN    NaN    NaN  fizz   NaN    NaN    NaN   \n",
       "\n",
       "                    5                     \n",
       "3                 Amy Anne Joseph Nikita  \n",
       "4                                         \n",
       "apple_fizz_7      NaN  NaN    NaN     35  \n",
       "banana_foo_2      NaN  NaN     50    NaN  \n",
       "cherimoya_baz_71  NaN   20    NaN    NaN  \n",
       "date_bar_24        30  NaN    NaN    NaN  ),\n",
       "                **{}\n",
       "               ), \n",
       "OpTrace(op_info=OpInfo(sid='/gen_pivot_args/Select@@1', gen_name='gen_pivot_args', op_type='Select', index=1, gen_group=None, uid=None, tags=None),\n",
       "        choice=4,\n",
       "        domain=[None, 0, 1, 2, 4, 5],\n",
       "        context=None,\n",
       "        **{}\n",
       "       ), \n",
       "OpTrace(op_info=OpInfo(sid='/gen_pivot_args/Select@@2', gen_name='gen_pivot_args', op_type='Select', index=2, gen_group=None, uid=None, tags=None),\n",
       "        choice=False,\n",
       "        domain=[True, False],\n",
       "        context=None,\n",
       "        **{}\n",
       "       ), \n",
       "OpTrace(op_info=OpInfo(sid='/gen_pivot_args/OrderedSubset@@1', gen_name='gen_pivot_args', op_type='OrderedSubset', index=1, gen_group=None, uid=None, tags=None),\n",
       "        choice=(1, 2, 5),\n",
       "        domain=[0, 1, 2, 5],\n",
       "        context=None,\n",
       "        **{}\n",
       "       )]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "from urllib.request import urlopen\n",
    "\n",
    "data = pickle.load(urlopen(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/training_data_pivot_columns.pkl\"))\n",
    "data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 2552.43it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2707.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Training model for OpInfo(sid='/gen_pivot_args/Select@select_columns@1', gen_name='gen_pivot_args', op_type='Select', index=1, gen_group=None, uid='select_columns', tags=None)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:317: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training(1/30)] Loss:  1.433152 Accuracy:  0.4720\n",
      "[Validation(1/30)] Loss:  1.241686 Accuracy:  0.3800\n",
      "[Training(2/30)] Loss:  1.322016 Accuracy:  0.4580\n",
      "[Validation(2/30)] Loss:  1.044748 Accuracy:  0.3300\n",
      "[Training(3/30)] Loss:  1.124238 Accuracy:  0.4480\n",
      "[Validation(3/30)] Loss:  1.082418 Accuracy:  0.3500\n",
      "[Training(4/30)] Loss:  1.123267 Accuracy:  0.4680\n",
      "[Validation(4/30)] Loss:  1.071257 Accuracy:  0.3900\n",
      "[Training(5/30)] Loss:  1.102100 Accuracy:  0.4720\n",
      "[Validation(5/30)] Loss:  1.030015 Accuracy:  0.3900\n",
      "[Training(6/30)] Loss:  1.062197 Accuracy:  0.4760\n",
      "[Validation(6/30)] Loss:  1.004234 Accuracy:  0.3900\n",
      "[Training(7/30)] Loss:  1.043536 Accuracy:  0.4800\n",
      "[Validation(7/30)] Loss:  0.992720 Accuracy:  0.3800\n",
      "[Training(8/30)] Loss:  1.030523 Accuracy:  0.4980\n",
      "[Validation(8/30)] Loss:  0.992106 Accuracy:  0.4000\n",
      "[Training(9/30)] Loss:  1.018177 Accuracy:  0.5020\n",
      "[Validation(9/30)] Loss:  0.987970 Accuracy:  0.4100\n",
      "[Training(10/30)] Loss:  1.005545 Accuracy:  0.5040\n",
      "[Validation(10/30)] Loss:  0.991990 Accuracy:  0.3900\n",
      "[Training(11/30)] Loss:  1.001968 Accuracy:  0.5060\n",
      "[Validation(11/30)] Loss:  1.000968 Accuracy:  0.4300\n",
      "[Training(12/30)] Loss:  0.998323 Accuracy:  0.5140\n",
      "[Validation(12/30)] Loss:  1.010648 Accuracy:  0.4300\n",
      "[Training(13/30)] Loss:  0.993639 Accuracy:  0.5300\n",
      "[Validation(13/30)] Loss:  1.024362 Accuracy:  0.4500\n",
      "[Training(14/30)] Loss:  0.987042 Accuracy:  0.5280\n",
      "[Validation(14/30)] Loss:  1.037082 Accuracy:  0.4700\n",
      "[Training(15/30)] Loss:  0.983957 Accuracy:  0.5440\n",
      "[Validation(15/30)] Loss:  1.012237 Accuracy:  0.4900\n",
      "[Training(16/30)] Loss:  0.963646 Accuracy:  0.5460\n",
      "[Validation(16/30)] Loss:  0.965060 Accuracy:  0.5100\n",
      "[Training(17/30)] Loss:  0.933991 Accuracy:  0.5600\n",
      "[Validation(17/30)] Loss:  0.936409 Accuracy:  0.5500\n",
      "[Training(18/30)] Loss:  0.917178 Accuracy:  0.5960\n",
      "[Validation(18/30)] Loss:  0.905520 Accuracy:  0.6000\n",
      "[Training(19/30)] Loss:  0.884501 Accuracy:  0.6220\n",
      "[Validation(19/30)] Loss:  0.875327 Accuracy:  0.6200\n",
      "[Training(20/30)] Loss:  0.846751 Accuracy:  0.6400\n",
      "[Validation(20/30)] Loss:  0.856619 Accuracy:  0.6300\n",
      "[Training(21/30)] Loss:  0.765619 Accuracy:  0.6680\n",
      "[Validation(21/30)] Loss:  0.826058 Accuracy:  0.6300\n",
      "[Training(22/30)] Loss:  0.687136 Accuracy:  0.7000\n",
      "[Validation(22/30)] Loss:  0.668685 Accuracy:  0.7000\n",
      "[Training(23/30)] Loss:  0.619863 Accuracy:  0.7260\n",
      "[Validation(23/30)] Loss:  0.633214 Accuracy:  0.7000\n",
      "[Training(24/30)] Loss:  0.530062 Accuracy:  0.7800\n",
      "[Validation(24/30)] Loss:  0.597910 Accuracy:  0.7200\n",
      "[Training(25/30)] Loss:  0.542301 Accuracy:  0.8000\n",
      "[Validation(25/30)] Loss:  0.461273 Accuracy:  0.8400\n",
      "[Training(26/30)] Loss:  0.427874 Accuracy:  0.8480\n",
      "[Validation(26/30)] Loss:  0.396331 Accuracy:  0.8600\n",
      "[Training(27/30)] Loss:  0.344740 Accuracy:  0.8920\n",
      "[Validation(27/30)] Loss:  0.249228 Accuracy:  0.8900\n",
      "[Training(28/30)] Loss:  0.242910 Accuracy:  0.9180\n",
      "[Validation(28/30)] Loss:  0.183535 Accuracy:  0.9300\n",
      "[Training(29/30)] Loss:  0.191365 Accuracy:  0.9360\n",
      "[Validation(29/30)] Loss:  0.154798 Accuracy:  0.9400\n",
      "[Training(30/30)] Loss:  0.117142 Accuracy:  0.9580\n",
      "[Validation(30/30)] Loss:  0.113996 Accuracy:  0.9600\n",
      "Restoring model with accuracy 0.9599999785423279 and loss 0.11399572342634201\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmpu24tscu2/model.weights\n"
     ]
    }
   ],
   "source": [
    "model = PivotGeneratorModel()\n",
    "train = data[:500]\n",
    "valid = data[500:]\n",
    "model.train(train, valid, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp, out).with_model(model):  # CHANGED : Using model\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Explored Till Now: {num_explored}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue\n",
    "            \n",
    "    print(f\"Total Number of Programs Explored: {num_explored}\")\n",
    "    print(f\"Total Number of Programs Crashed: {num_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for operator /gen_pivot_args/Select@select_columns@1\n",
      "[('Category', 0.9999907), ('Expense', 8.901682e-06), ('Date', 2.2617908e-07), ('Added By', 2.7232154e-09), ('Location', 1.2903171e-09), ('Balance', 5.8135863e-10)]\n",
      "Found Solution! inp.pivot(index='Date', columns='Category', values='Expense')\n",
      "Time to solution:  1.017 seconds\n",
      "Number of Programs Explored Till Now: 336\n",
      "Total Number of Programs Explored: 4056\n",
      "Total Number of Programs Crashed: 138\n"
     ]
    }
   ],
   "source": [
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! The model for the first `Select` helped it pick the right value in the first try (and with 99% confidence) which significantly improved the search time. Why stop at using a model for only one `Select`. We can use models for all the operators!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Defining a Model for All Operators\n",
    "\n",
    "First let's give the same context to all the operators and not just the first `Select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame, output_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns), context=(input_df, output_df))\n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in list(input_df.columns) if i != arg_columns], context=(input_df, output_df))\n",
    "\n",
    "    # Select one of columns or list of columns\n",
    "    if Select([True, False], context=(input_df, output_df), uid=\"branch\"):\n",
    "        arg_values = Select([None] + [i for i in list(input_df.columns) if i != arg_columns and i != arg_index],\n",
    "                            context=(input_df, output_df))\n",
    "    else:\n",
    "        arg_values = list(OrderedSubset([i for i in list(input_df.columns) if i != arg_columns and i != arg_index],\n",
    "                                        context=(input_df, output_df)))\n",
    "\n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model as before, covering all the operators this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_config = {\n",
    "    'learning_rate': 0.01,\n",
    "    'node_dimension': 50,\n",
    "    'classifier_hidden_dims': [50],\n",
    "    'batch_size': 30000,\n",
    "    'layer_timesteps': [1, 1, 1]\n",
    "}\n",
    "\n",
    "class PivotGeneratorModel(IndependentOperatorsModel):\n",
    "    @operator\n",
    "    def Select(*args, **kwargs):\n",
    "        return PivotSelectModel(common_config)\n",
    "\n",
    "    @operator(name='Select', uid=\"branch\")\n",
    "    def SelectBranch(*args, **kwargs):\n",
    "        return PivotClassifyModel(common_config, domain_size=2)\n",
    "\n",
    "    @operator\n",
    "    def OrderedSubset(*args, **kwargs):\n",
    "        return PivotOrderedSubsetModel(common_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can train the model using the following commands.\n",
    "\n",
    "```python\n",
    "model = PivotGeneratorModel()\n",
    "data = pickle.load(urlopen(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/training_data_pivot_full.pkl\"))\n",
    "train_data = data[:500]\n",
    "valid_data = data[500:]\n",
    "model.train(train_data, valid_data, num_epochs=100)\n",
    "```\n",
    "\n",
    "Since training for 100 epochs would take some time, we'll load a pre-trained model (obtained through the same set of commands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmp3_e7yk6c/models/gen_pivot_args/Select@@1/model.weights\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmp3_e7yk6c/models/gen_pivot_args/Select@@2/model.weights\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmp3_e7yk6c/models/gen_pivot_args/Select@branch@1/model.weights\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmp3_e7yk6c/models/gen_pivot_args/Select@@3/model.weights\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmp3_e7yk6c/models/gen_pivot_args/OrderedSubset@@1/model.weights\n"
     ]
    }
   ],
   "source": [
    "from atlas.models.utils import restore_model\n",
    "model = restore_model(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/pandas-pivot-model-full.zip\", from_url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='Date', columns='Category', values='Expense')\n",
      "Time to solution:  0.037 seconds\n",
      "Number of Programs Explored Till Now: 1\n",
      "Total Number of Programs Explored: 2736\n",
      "Total Number of Programs Crashed: 140\n"
     ]
    }
   ],
   "source": [
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='foo', columns='bar', values='baz')\n",
      "Time to solution:  0.034 seconds\n",
      "Number of Programs Explored Till Now: 1\n",
      "Total Number of Programs Explored: 48\n",
      "Total Number of Programs Crashed: 0\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "  'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n",
    "  'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "  'baz': [10, 20, 30, 40, 50, 60],\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    'A': {'one': 10, 'two': 40},\n",
    "    'B': {'one': 20, 'two': 50},\n",
    "    'C': {'one': 30, 'two': 60}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our synthesizer gets it right on the first try on both occasions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've learnt to express a search space using generators in Atlas. A Generator is a regular Python function which uses some special operators to capture non-deterministic decisions (such as selecting one element from a list). We built a generator for the `pivot` function in Pandas which helped us construct a synthesizer, which works fine for small inputs but suffers on large ones as the search space is too large. We then used graph-based neural-network models to *guide* the generator towards programs in the search space that are most likely to produce the output given the input. In fact, our learned synthesizer gets the correct program on the first try."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
