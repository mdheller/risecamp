{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## AutoPandas\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/autopandas-logo.png\" alt=\"AutoPandas Logo\" style=\"width: 10%; float: left; padding: 10px\"/>\n",
    "\n",
    "\n",
    "[AutoPandas](https://autopandas.io) is a input-output example based synthesis engine for the [Pandas](https://pandas.pydata.org) data-analytics library in Python. Users provide input-output pairs (dataframes) specifying their intent, and the AutoPandas engine searches for programs using the Pandas library that transform the input to the output.\n",
    "\n",
    "## Atlas\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/atlas-logo.png\" alt=\"AutoPandas Logo\" style=\"width: 10%; float: left; padding: 10px\"/>\n",
    "\n",
    "[Atlas](https://github.com/rbavishi/atlas) is the framework instantiating AutoPandas. It generalizes the key ideas behind its synthesis engine making it possible to apply them to build engines for entirely new domains such as other APIs like Numpy or Tensorflow, or domain-specific languages (DSLs) for say string-manipulation. The core concept in Atlas is that of a *generator*, which you will learn about shortly. Generators are not only useful in synthesis, but have potential applications in testing as well.\n",
    "\n",
    "## What are we going to learn?\n",
    "\n",
    "Pandas is a huge library, and building a synthesizer for the entirety of Pandas is out-of-scope for the tutorial.\n",
    "Instead we will pick a single function in Pandas, namely `pivot`, and try to build an efficient synthesizer for it. That is, given input and output dataframes, our synthesizer will determine the right arguments to the `pivot` function.\n",
    "\n",
    "We will be using the the abstractions provided by Atlas and in doing so, we hope to motivate why we feel these abstractions are useful for instantiating engines for other domains.\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. What is Pivoting?\n",
    "\n",
    "Pivot is a summarization operation on tables that is very useful for certain kinds of queries. It is best explained using a concrete example. It is inspired from the example provided [here](https://kite.com/blog/python/pandas-pivot-table/).\n",
    "\n",
    "Suppose you are working on stock-market data that looks something like the following -\n",
    "\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/stocks-input.png\" alt=\"Pivot Documentation\" style=\"width: 30%;\"/>.\n",
    "\n",
    "It is hard to compare trade volume of stocks on different dates in this particular form. Specifically, it is difficult to glean information when the data is presented in this particular format. `Pivot` is a useful transformation to alleviate this issue. We can `pivot` on the `date` column, keeping index as the `symbol` column and rearranging the `volume` column accordingly as follows - \n",
    "\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/stocks-output.png\" alt=\"Pivot Documentation\" style=\"width: 40%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Synthesis Task\n",
    "\n",
    "The user provides input dataframe(s) as well as an output dataframe. Our system should be able to produce a call or a sequence of calls using `pivot`, `groupby` and various aggregation functions that transform the input to the desired output. Here is another example - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>6167358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>3681522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>3996001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>27436203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>19737419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>20810384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>1446047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>1443174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>1099289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date    volume\n",
       "0   AMZN  2019-03-04   6167358\n",
       "1   AMZN  2019-03-05   3681522\n",
       "2   AMZN  2019-03-06   3996001\n",
       "3   AAPL  2019-03-04  27436203\n",
       "4   AAPL  2019-03-05  19737419\n",
       "5   AAPL  2019-03-06  20810384\n",
       "6   GOOG  2019-03-04   1446047\n",
       "7   GOOG  2019-03-05   1443174\n",
       "8   GOOG  2019-03-06   1099289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019-03-04</th>\n",
       "      <th>2019-03-05</th>\n",
       "      <th>2019-03-06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>27436203</td>\n",
       "      <td>19737419</td>\n",
       "      <td>20810384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>6167358</td>\n",
       "      <td>3681522</td>\n",
       "      <td>3996001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1446047</td>\n",
       "      <td>1443174</td>\n",
       "      <td>1099289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2019-03-04  2019-03-05  2019-03-06\n",
       "AAPL    27436203    19737419    20810384\n",
       "AMZN     6167358     3681522     3996001\n",
       "GOOG     1446047     1443174     1099289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write a method `synthesize_pivot` that when run on the input-output example as follows -\n",
    "\n",
    "```python\n",
    "synthesize_pivot(inp_df, out_df)\n",
    "```\n",
    "\n",
    "returns the following program or an equivalent program\n",
    "\n",
    "```python\n",
    "inp_df.pivot(index=\"symbol\", columns=\"date\", values=\"volume\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A Brute-Force Synthesizer for Pivot\n",
    "\n",
    "Before we start building our synthesizer, we need to know the space of programs we are going to search over.\n",
    "\n",
    "### (a) What are the Possible Programs?\n",
    "\n",
    "Here's the documentation for pivot -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation for **Pivot**\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/pandas-pivot-doc.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information here! But here are the key points to help us get started -\n",
    "\n",
    "1. The `index` must be one of the columns of the input table or the value `None`.\n",
    "2. The `columns` argument must only be one of the columns and NOT `None`.\n",
    "3. The `values` argument must also be one of the columns or `None`. It can also be a list of columns.\n",
    "\n",
    "The set of possible arguments to `pivot` is therefore the cross-product of all the possible values for each of the arguments (`index`, `columns` and `pivot`) individually. How can we express this succintly? Now comes in the concept of a `generator` in Atlas/AutoPandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Introduction to Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlas import generator\n",
    "\n",
    "@generator\n",
    "def gen_column_tuples(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Produces all possible 2-tuples of column names\n",
    "    \"\"\"\n",
    "    col1 = Select(df.columns)  # Select one of the columns\n",
    "    col2 = Select(df.columns)  # Select one of the columns\n",
    "    \n",
    "    return (col1, col2)  # Construct the tuple and return\n",
    "\n",
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "# Print all possible tuples that can be returned by gen_column_tuples\n",
    "# In this case all 3x3 = 9 tuples will be returned\n",
    "for result in gen_column_tuples.generate(inp_df):\n",
    "    print(\"Tuple :\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Select` operator is provided by Atlas. Given a list of values, it returns *one* of the values as the result. The `@generator` transforms any function into an Atlas Generator and overloads any calls to operators like `Select`. One can call `generate(*args, **kwargs)` on such a generator to get an iterator that returns the result of all possible executions of the generator (as governed by the calls to `Select`).\n",
    "\n",
    "By default, the iterator has **depth-first behavior**. That is, later calls to `Select` explore all possibilities before the previous `Select` calls.\n",
    "\n",
    "**NOTE** : An Atlas `generator` is different from the Python Generator. Everything that can be expressed using a python generator can be expressed as an Atlas generator. The power of Atlas generators is in combining these generators with probabilistic models as we will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) A Generator for Pivot Arguments\n",
    "\n",
    "At this point, you should have a fair idea of how to encode the constraints described in **2.(a)** using a generator. Let us try to write a generator for the arguments to the `pivot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns))\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + list(input_df.columns))\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]):\n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + list(input_df.columns))\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset(list(input_df.columns)))\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also ready to write the `synthesize_pivot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_equal(df1, df2):\n",
    "    try:\n",
    "        pd.testing.assert_frame_equal(df1, df2, check_names=False)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def synthesize_pivot(inp, out):\n",
    "    for args in gen_pivot_args.generate(inp):\n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on the example we had in **Section 1**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Analysis\n",
    "\n",
    "Let us log some statistics about our `synthesize_pivot` routine. In particular, let's track the number of programs explored, time taken and number of exceptions raised (while executing the program)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp):\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Explored Till Now: {num_explored}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue\n",
    "            \n",
    "    print(f\"Total Number of Programs Explored: {num_explored}\")\n",
    "    print(f\"Total Number of Programs Crashed: {num_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution was produced fairly quickly. But `57` of the `228` argument combinations returned by our generator `gen_pivot` errored out! This means our synthesizer is wasting time evaluating programs that do not even produce an output. Can we could optimize our synthesizer to avoid wasting time on these programs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Incorporating Domain-Specific Constraints in Generator\n",
    "\n",
    "Can we exploit our knowledge of the pivot function to avoid enumerating these programs? Turns out, a meaningful `pivot` program satisfies the following -\n",
    "\n",
    "1. `columns` and `index` argument cannot be equal\n",
    "2. The column(s) in `values` must be different from both `columns` and `index`.\n",
    "\n",
    "It is very easy to incorporate these constraints in the generator as it is regular Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns))\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in input_df.columns if i != arg_columns]) # CONSTRAINT-1\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]):\n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + [i for i in input_df.columns if i not in {arg_columns, arg_index}]) # CONSTRAINT-2\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset([i for i in input_df.columns if i not in {arg_columns, arg_index}])) # CONSTRAINT-2\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! We are getting to the solution much faster as we are not wasting time exploring bad programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Handling Big DataFrames\n",
    "\n",
    "We are still doing a brute-force search. Performance would suffer if the space of possible programs itself is pretty large. In the case of `pivot`, what happens if our dataframe has a large number of columns? In the running example, it is more realistic to have other columns in the table as well as, that may not be relevant to a particular query. For example, for stocks, it is common to have columns for opening and closing values, as well as highs and lows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1655.13</td>\n",
       "      <td>1674.26</td>\n",
       "      <td>1651.00</td>\n",
       "      <td>1671.73</td>\n",
       "      <td>4974877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>1685.00</td>\n",
       "      <td>1709.43</td>\n",
       "      <td>1674.36</td>\n",
       "      <td>1696.17</td>\n",
       "      <td>6167358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>1702.95</td>\n",
       "      <td>1707.80</td>\n",
       "      <td>1689.01</td>\n",
       "      <td>1692.43</td>\n",
       "      <td>3681522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>174.28</td>\n",
       "      <td>175.15</td>\n",
       "      <td>172.89</td>\n",
       "      <td>174.97</td>\n",
       "      <td>25886167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>175.69</td>\n",
       "      <td>177.75</td>\n",
       "      <td>173.97</td>\n",
       "      <td>175.85</td>\n",
       "      <td>27436203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>175.94</td>\n",
       "      <td>176.00</td>\n",
       "      <td>174.54</td>\n",
       "      <td>175.53</td>\n",
       "      <td>19737419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1124.90</td>\n",
       "      <td>1142.97</td>\n",
       "      <td>1124.75</td>\n",
       "      <td>1140.99</td>\n",
       "      <td>1450316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>1146.99</td>\n",
       "      <td>1158.28</td>\n",
       "      <td>1130.69</td>\n",
       "      <td>1147.80</td>\n",
       "      <td>1446047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>1150.06</td>\n",
       "      <td>1169.61</td>\n",
       "      <td>1146.19</td>\n",
       "      <td>1162.03</td>\n",
       "      <td>1443174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date     open     high      low    close    volume\n",
       "0   AMZN  2019-03-01  1655.13  1674.26  1651.00  1671.73   4974877\n",
       "1   AMZN  2019-03-04  1685.00  1709.43  1674.36  1696.17   6167358\n",
       "2   AMZN  2019-03-05  1702.95  1707.80  1689.01  1692.43   3681522\n",
       "3   AAPL  2019-03-01   174.28   175.15   172.89   174.97  25886167\n",
       "4   AAPL  2019-03-04   175.69   177.75   173.97   175.85  27436203\n",
       "5   AAPL  2019-03-05   175.94   176.00   174.54   175.53  19737419\n",
       "6   GOOG  2019-03-01  1124.90  1142.97  1124.75  1140.99   1450316\n",
       "7   GOOG  2019-03-04  1146.99  1158.28  1130.69  1147.80   1446047\n",
       "8   GOOG  2019-03-05  1150.06  1169.61  1146.19  1162.03   1443174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019-03-01</th>\n",
       "      <th>2019-03-04</th>\n",
       "      <th>2019-03-05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>25886167</td>\n",
       "      <td>27436203</td>\n",
       "      <td>19737419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>4974877</td>\n",
       "      <td>6167358</td>\n",
       "      <td>3681522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1450316</td>\n",
       "      <td>1446047</td>\n",
       "      <td>1443174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2019-03-01  2019-03-04  2019-03-05\n",
       "AAPL    25886167    27436203    19737419\n",
       "AMZN     4974877     6167358     3681522\n",
       "GOOG     1450316     1446047     1443174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-01', '2019-03-04', '2019-03-05', \n",
    "             '2019-03-01', '2019-03-04', '2019-03-05', \n",
    "             '2019-03-01', '2019-03-04', '2019-03-05'],\n",
    "    'open': [1655.13, 1685.0, 1702.95, 174.28, 175.69, 175.94, 1124.9, 1146.99, 1150.06], \n",
    "    'high': [1674.26, 1709.43, 1707.8, 175.15, 177.75, 176.0, 1142.97, 1158.28, 1169.61], \n",
    "    'low': [1651.0, 1674.36, 1689.01, 172.89, 173.97, 174.54, 1124.75, 1130.69, 1146.19], \n",
    "    'close': [1671.73, 1696.17, 1692.43, 174.97, 175.85, 175.53, 1140.99, 1147.8, 1162.03], \n",
    "    'volume': [4974877, 6167358, 3681522, 25886167, 27436203, 19737419, 1450316, 1446047, 1443174],\n",
    "    \n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    '2019-03-01': {'AAPL': 25886167, 'AMZN': 4974877, 'GOOG': 1450316},\n",
    "    '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    "    '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174}\n",
    "})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! That is quite a bit slow. If we wanted to build a synthesis service where people can get their input-output queries answered in real-time, this approach would definitely not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a Generator\n",
    "\n",
    "The order of argument combinations returned by `gen_pivot` is governed by the order of values returned by the individual operators (four `Select`s and one `OrderedSubset`). Therefore, to speed up our synthesizer, the operators need to return the correct values *first*. \n",
    "\n",
    "#### Can we train the individual operators to return values **smartly** i.e. adjust the order in which they return values based on the input-output example?\n",
    "##### For the purpose of the tutorial, let's focus on the first call to `Select` i.e. the operator that decides the value of the `columns` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Adding Input-Output Example as the Context\n",
    "\n",
    "In order to train the operator, we first need to provide access to the input-output example. Currently only `inp_df` is passed as an argument to the generator `gen_pivot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame, output_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns), context=(input_df, output_df),  # ADDING CONTEXT HERE\n",
    "                         uid=\"select_columns\") # Adding uid to aid identification while defining model\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in input_df.columns if i != arg_columns])\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]):\n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + [i for i in input_df.columns if i not in {arg_columns, arg_index}])\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset([i for i in input_df.columns if i not in {arg_columns, arg_index}]))\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp, out):  # CHANGED : PASSING out AS AN ARGUMENT\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Tried: {num_explored}\")\n",
    "                \n",
    "                break  # CHANGED : Stop at first solution\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Defining the Model\n",
    "\n",
    "We are going to use a Graph-Neural-Network model for our Select operator. Covering this model is out-of-scope for this tutorial, but here are the key insights behind using this model.\n",
    "\n",
    "1. The transformation represented by an input-output example consisting of dataframes is a function of the relationships between the values in the input and the values in the output, rather the concrete values themselves.  For example, the concrete column names `Category`, `Expense` etc. are irrelevant. It is their position in the output dataframe that really captures the transformation.\n",
    "\n",
    "2. We can represent dataframes as a graph where each column, cell and index value is represented as a node, and edges represent relationships amongst these nodes. The nodes are labeled with the type of the value (int, str etc.) rather than the value itself. For example, each column node will have a `COLUMN` edge to all the cell nodes in the corresponding column. We will also have an `EQUALITY` edge between between each pair of nodes that have the same concrete value.\n",
    "\n",
    "Here is a graphical representation of the graph encoding for the given input and output dataframe along with the domain for the `Select` operator we're trying to learn a model for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/input-output-example.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/graph-encoding-example.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the model for the generator. For more details, refer to the `models.py` file in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlas.models.imitation import IndependentOperatorsModel\n",
    "from atlas.operators import operator\n",
    "from models import PivotSelectModel\n",
    "\n",
    "class PivotGeneratorModel(IndependentOperatorsModel):\n",
    "    @operator(name='Select', uid=\"select_columns\")\n",
    "    def SelectColumns(*args, **kwargs):\n",
    "        config = {\n",
    "            'learning_rate': 0.01,\n",
    "            'node_dimension': 50,\n",
    "            'classifier_hidden_dims': [50],\n",
    "            'batch_size': 30000,  # number of nodes in a batch\n",
    "            'layer_timesteps': [1, 1, 1]\n",
    "        }\n",
    "\n",
    "        return PivotSelectModel(config, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training Data\n",
    "\n",
    "Training data for our purposes consists of **traces** of generator executions that produce the correct program given an input-output example. These traces store the correct choices made by the operators and hence are suffice as training data for the operators.\n",
    "\n",
    "**NOTE:** This is only for illustration purposes, so you should not worry too much about understanding the format of these traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from urllib.request import urlopen\n",
    "\n",
    "data = pickle.load(urlopen(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/training_data_pivot_columns.pkl\"))\n",
    "data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PivotGeneratorModel()\n",
    "train = data[:500]\n",
    "valid = data[500:]\n",
    "model.train(train, valid, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp, out).with_model(model):  # CHANGED : Using model\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Tried: {num_explored}\")\n",
    "                \n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! The model for the first `Select` helped it pick the right value in the first try (and with >95% confidence) which significantly improved the search time. Why stop at using a model for only one `Select`. We can use models for all the operators!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Defining a Model for All Operators\n",
    "\n",
    "First let's give the same context to all the operators and not just the first `Select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame, output_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns), context=(input_df, output_df))\n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in list(input_df.columns) if i != arg_columns], context=(input_df, output_df))\n",
    "\n",
    "    # Select one of columns or list of columns\n",
    "    if Select([True, False], context=(input_df, output_df), uid=\"branch\"):\n",
    "        arg_values = Select([None] + [i for i in list(input_df.columns) if i != arg_columns and i != arg_index],\n",
    "                            context=(input_df, output_df))\n",
    "    else:\n",
    "        arg_values = list(OrderedSubset([i for i in list(input_df.columns) if i != arg_columns and i != arg_index],\n",
    "                                        context=(input_df, output_df)))\n",
    "\n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model as before, covering all the operators this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_config = {\n",
    "    'learning_rate': 0.01,\n",
    "    'node_dimension': 50,\n",
    "    'classifier_hidden_dims': [50],\n",
    "    'batch_size': 30000,\n",
    "    'layer_timesteps': [1, 1, 1]\n",
    "}\n",
    "\n",
    "class PivotGeneratorModel(IndependentOperatorsModel):\n",
    "    @operator\n",
    "    def Select(*args, **kwargs):\n",
    "        return PivotSelectModel(common_config)\n",
    "\n",
    "    @operator(name='Select', uid=\"branch\")\n",
    "    def SelectBranch(*args, **kwargs):\n",
    "        return PivotClassifyModel(common_config, domain_size=2)\n",
    "\n",
    "    @operator\n",
    "    def OrderedSubset(*args, **kwargs):\n",
    "        return PivotOrderedSubsetModel(common_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can train the model using the following commands.\n",
    "\n",
    "```python\n",
    "model = PivotGeneratorModel()\n",
    "data = pickle.load(urlopen(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/training_data_pivot_full.pkl\"))\n",
    "train_data = data[:500]\n",
    "valid_data = data[500:]\n",
    "model.train(train_data, valid_data, num_epochs=100)\n",
    "```\n",
    "\n",
    "Since training for 100 epochs would take some time, we'll load a pre-trained model (obtained through the same set of commands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlas.models.utils import restore_model\n",
    "model = restore_model(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/pandas-pivot-model-full.zip\", from_url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-01', '2019-03-04', '2019-03-05', \n",
    "             '2019-03-01', '2019-03-04', '2019-03-05', \n",
    "             '2019-03-01', '2019-03-04', '2019-03-05'],\n",
    "    'open': [1655.13, 1685.0, 1702.95, 174.28, 175.69, 175.94, 1124.9, 1146.99, 1150.06], \n",
    "    'high': [1674.26, 1709.43, 1707.8, 175.15, 177.75, 176.0, 1142.97, 1158.28, 1169.61], \n",
    "    'low': [1651.0, 1674.36, 1689.01, 172.89, 173.97, 174.54, 1124.75, 1130.69, 1146.19], \n",
    "    'close': [1671.73, 1696.17, 1692.43, 174.97, 175.85, 175.53, 1140.99, 1147.8, 1162.03], \n",
    "    'volume': [4974877, 6167358, 3681522, 25886167, 27436203, 19737419, 1450316, 1446047, 1443174],\n",
    "    \n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    '2019-03-01': {'AAPL': 25886167, 'AMZN': 4974877, 'GOOG': 1450316},\n",
    "    '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    "    '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our synthesizer gets it right on the first try on both occasions! Here are some more examples involving different dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "  'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n",
    "  'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "  'baz': [10, 20, 30, 40, 50, 60],\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    'A': {'one': 10, 'two': 40},\n",
    "    'B': {'one': 20, 'two': 50},\n",
    "    'C': {'one': 30, 'two': 60}\n",
    "})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'Date': {0: '2018-02-18', 1: '2018-02-18', 2: '2018-02-24', 3: '2018-02-24'},\n",
    "    'Location': {0: 'Terrace', 1: 'Pox', 2: 'Gate 320', 3: 'Pox'},\n",
    "    'Balance': {0: 9971.66, 1: 9726.03, 2: 9604.14, 3: 9356.04},\n",
    "    'Added By': {0: 'Theresa', 1: 'Margaret', 2: 'Helena', 3:'Katherine'},\n",
    "    'Expense': {0: 98.34, 1: 245.63, 2: 121.89, 3: 248.0},\n",
    "    'Category': {0: 'Social', 1: 'Lunch', 2: 'Social', 3: 'Lunch'}})\n",
    "\n",
    "out_df = pd.DataFrame({'Lunch': {'2018-02-18': 245.63, '2018-02-24': 248.0},\n",
    " 'Social': {'2018-02-18': 98.34, '2018-02-24': 121.89}})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've learnt to express a search space using generators in Atlas. A Generator is a regular Python function which uses some special operators to capture non-deterministic decisions (such as selecting one element from a list). We built a generator for the `pivot` function in Pandas which helped us construct a synthesizer, which works fine for small inputs but suffers on large ones as the search space is too large. We then used graph-based neural-network models to *guide* the generator towards programs in the search space that are most likely to produce the output given the input. In fact, our learned synthesizer gets the correct program on the first try."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
