{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## AutoPandas\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/autopandas-logo.png\" alt=\"AutoPandas Logo\" style=\"width: 10%; float: left; padding: 10px\"/>\n",
    "\n",
    "\n",
    "[AutoPandas](https://autopandas.io) is a input-output example based synthesis engine for the [Pandas](https://pandas.pydata.org) data-analytics library in Python. Users provide input-output pairs (dataframes) specifying their intent, and the AutoPandas engine searches for programs using the Pandas library that transform the input to the output.\n",
    "\n",
    "## Atlas\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/atlas-logo.png\" alt=\"AutoPandas Logo\" style=\"width: 10%; float: left; padding: 10px\"/>\n",
    "\n",
    "[Atlas](https://github.com/rbavishi/atlas) is the framework instantiating AutoPandas. It generalizes the key ideas behind its synthesis engine making it possible to apply them to build engines for entirely new domains such as other APIs like Numpy or Tensorflow, or domain-specific languages (DSLs) for say string-manipulation. The core concept in Atlas is that of a *generator*, which you will learn about shortly. Generators are not only useful in synthesis, but have potential applications in testing as well.\n",
    "\n",
    "## What are we going to learn?\n",
    "\n",
    "Pandas is a huge library, and building a synthesizer for the entirety of Pandas is out-of-scope for the tutorial.\n",
    "Instead we will pick a single function in Pandas, namely `pivot`, and try to build an efficient synthesizer for it. That is, given input and output dataframes, our synthesizer will determine the right arguments to the `pivot` function.\n",
    "\n",
    "We will be using the the abstractions provided by Atlas and in doing so, we hope to motivate why we feel these abstractions are useful for instantiating engines for other domains.\n",
    "\n",
    "----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. What is Pivoting?\n",
    "\n",
    "Pivot is a summarization operation on tables that is very useful for certain kinds of queries. It is best explained using a concrete example. It is inspired from the example provided [here](https://kite.com/blog/python/pandas-pivot-table/).\n",
    "\n",
    "Suppose you are working on stock-market data that looks something like the following -\n",
    "\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/stocks-input.png\" alt=\"Pivot Documentation\" style=\"width: 30%;\"/>.\n",
    "\n",
    "It is hard to compare trade volume of stocks on different dates in this particular form. Specifically, it is difficult to glean information when the data is presented in this particular format. `Pivot` is a useful transformation to alleviate this issue. We can `pivot` on the `date` column, keeping index as the `symbol` column and rearranging the `volume` column accordingly as follows - \n",
    "\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/stocks-output.png\" alt=\"Pivot Documentation\" style=\"width: 40%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Synthesis Task\n",
    "\n",
    "The user provides input dataframe(s) as well as an output dataframe. Our system should be able to produce a call or a sequence of calls using `pivot`, `groupby` and various aggregation functions that transform the input to the desired output. Here is another example - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>6167358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>3681522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>3996001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>27436203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>19737419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>20810384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>1446047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>1443174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>1099289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date    volume\n",
       "0   AMZN  2019-03-04   6167358\n",
       "1   AMZN  2019-03-05   3681522\n",
       "2   AMZN  2019-03-06   3996001\n",
       "3   AAPL  2019-03-04  27436203\n",
       "4   AAPL  2019-03-05  19737419\n",
       "5   AAPL  2019-03-06  20810384\n",
       "6   GOOG  2019-03-04   1446047\n",
       "7   GOOG  2019-03-05   1443174\n",
       "8   GOOG  2019-03-06   1099289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019-03-04</th>\n",
       "      <th>2019-03-05</th>\n",
       "      <th>2019-03-06</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>27436203</td>\n",
       "      <td>19737419</td>\n",
       "      <td>20810384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>6167358</td>\n",
       "      <td>3681522</td>\n",
       "      <td>3996001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1446047</td>\n",
       "      <td>1443174</td>\n",
       "      <td>1099289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2019-03-04  2019-03-05  2019-03-06\n",
       "AAPL    27436203    19737419    20810384\n",
       "AMZN     6167358     3681522     3996001\n",
       "GOOG     1446047     1443174     1099289"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write a method `synthesize_pivot` that when run on the input-output example as follows -\n",
    "\n",
    "```python\n",
    "synthesize_pivot(inp_df, out_df)\n",
    "```\n",
    "\n",
    "returns the following program or an equivalent program\n",
    "\n",
    "```python\n",
    "inp_df.pivot(index=\"symbol\", columns=\"date\", values=\"volume\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A Brute-Force Synthesizer for Pivot\n",
    "\n",
    "Before we start building our synthesizer, we need to know the space of programs we are going to search over.\n",
    "\n",
    "### (a) What are the Possible Programs?\n",
    "\n",
    "Here's the documentation for pivot -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation for **Pivot**\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/pandas-pivot-doc.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of information here! But here are the key points to help us get started -\n",
    "\n",
    "1. The `index` must be one of the columns of the input table or the value `None`.\n",
    "2. The `columns` argument must only be one of the columns and NOT `None`.\n",
    "3. The `values` argument must also be one of the columns or `None`. It can also be a list of columns.\n",
    "\n",
    "The set of possible arguments to `pivot` is therefore the cross-product of all the possible values for each of the arguments (`index`, `columns` and `pivot`) individually. How can we express this succintly? Now comes in the concept of a `generator` in Atlas/AutoPandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Introduction to Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuple : ('symbol', 'symbol')\n",
      "Tuple : ('symbol', 'date')\n",
      "Tuple : ('symbol', 'volume')\n",
      "Tuple : ('date', 'symbol')\n",
      "Tuple : ('date', 'date')\n",
      "Tuple : ('date', 'volume')\n",
      "Tuple : ('volume', 'symbol')\n",
      "Tuple : ('volume', 'date')\n",
      "Tuple : ('volume', 'volume')\n"
     ]
    }
   ],
   "source": [
    "from atlas import generator\n",
    "\n",
    "@generator\n",
    "def gen_column_tuples(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Produces all possible 2-tuples of column names\n",
    "    \"\"\"\n",
    "    col1 = Select(df.columns)  # Select one of the columns\n",
    "    col2 = Select(df.columns)  # Select one of the columns\n",
    "    \n",
    "    return (col1, col2)  # Construct the tuple and return\n",
    "\n",
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "# Print all possible tuples that can be returned by gen_column_tuples\n",
    "# In this case all 3x3 = 9 tuples will be returned\n",
    "for result in gen_column_tuples.generate(inp_df):\n",
    "    print(\"Tuple :\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Select` operator is provided by Atlas. Given a list of values, it returns *one* of the values as the result. The `@generator` transforms any function into an Atlas Generator and overloads any calls to operators like `Select`. One can call `generate(*args, **kwargs)` on such a generator to get an iterator that returns the result of all possible executions of the generator (as governed by the calls to `Select`).\n",
    "\n",
    "By default, the iterator has **depth-first behavior**. That is, later calls to `Select` explore all possibilities before the previous `Select` calls.\n",
    "\n",
    "**NOTE** : An Atlas `generator` is different from the Python Generator. Everything that can be expressed using a python generator can be expressed as an Atlas generator. The power of Atlas generators is in combining these generators with probabilistic models as we will see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) A Generator for Pivot Arguments\n",
    "\n",
    "At this point, you should have a fair idea of how to encode the constraints described in **2.(a)** using a generator. Let us try to write a generator for the arguments to the `pivot` function.\n",
    "\n",
    "**Exercise:** Fill in the missing arguments to the two `Select` calls shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns))\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + list(input_df.columns))\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]): # TODO : FILL IN THE ARGUMENTS\n",
    "        \n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + list(input_df.columns)) # TODO : FILL IN THE ARGUMENTS\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset(list(input_df.columns)))\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also ready to write the `synthesize_pivot` function.\n",
    "\n",
    "**Exercise:** Fill in the code for the iterator as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_equal(df1, df2):\n",
    "    try:\n",
    "        pd.testing.assert_frame_equal(df1, df2, check_names=False)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def synthesize_pivot(inp, out):\n",
    "    for args in gen_pivot_args.generate(inp): # TODO : Fill in the expression for the iterator.\n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "        except Exception as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out on the example we had in **Section 1**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='symbol', columns='date', values='volume')\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Analysis\n",
    "\n",
    "Let us log some statistics about our `synthesize_pivot` routine. In particular, let's track the number of programs explored, time taken and number of exceptions raised (while executing the program)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp):\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Explored Till Now: {num_explored}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue\n",
    "            \n",
    "    print(f\"Total Number of Programs Explored: {num_explored}\")\n",
    "    print(f\"Total Number of Programs Crashed: {num_errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='symbol', columns='date', values='volume')\n",
      "Time to solution:  0.194 seconds\n",
      "Number of Programs Explored Till Now: 99\n",
      "Total Number of Programs Explored: 228\n",
      "Total Number of Programs Crashed: 57\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution was produced fairly quickly. But `57` of the `228` argument combinations returned by our generator `gen_pivot` errored out! This means our synthesizer is wasting time evaluating programs that do not even produce an output. Can we could optimize our synthesizer to avoid wasting time on these programs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Incorporating Domain-Specific Constraints in Generator\n",
    "\n",
    "Can we exploit our knowledge of the pivot function to avoid enumerating these programs? Turns out, a meaningful `pivot` program satisfies the following -\n",
    "\n",
    "1. `columns` and `index` argument cannot be equal\n",
    "2. The column(s) in `values` must be different from both `columns` and `index`.\n",
    "\n",
    "It is very easy to incorporate these constraints in the generator as it is regular Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns))\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in input_df.columns if i != arg_columns]) # CONSTRAINT-1\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]):\n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + [i for i in input_df.columns if i not in {arg_columns, arg_index}]) # CONSTRAINT-2\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset([i for i in input_df.columns if i not in {arg_columns, arg_index}])) # CONSTRAINT-2\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='symbol', columns='date', values='volume')\n",
      "Time to solution:  0.067 seconds\n",
      "Number of Programs Explored Till Now: 22\n",
      "Total Number of Programs Explored: 39\n",
      "Total Number of Programs Crashed: 0\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! We are getting to the solution much faster as we are not wasting time exploring bad programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Handling Big DataFrames\n",
    "\n",
    "We are still doing a brute-force search. Performance would suffer if the space of possible programs itself is pretty large. In the case of `pivot`, what happens if our dataframe has a large number of columns? In the running example, it is more realistic to have other columns in the table as well as, that may not be relevant to a particular query. For example, for stocks, it is common to have columns for opening and closing values, as well as highs and lows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1655.13</td>\n",
       "      <td>1674.26</td>\n",
       "      <td>1651.00</td>\n",
       "      <td>1671.73</td>\n",
       "      <td>4974877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>1685.00</td>\n",
       "      <td>1709.43</td>\n",
       "      <td>1674.36</td>\n",
       "      <td>1696.17</td>\n",
       "      <td>6167358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>1702.95</td>\n",
       "      <td>1707.80</td>\n",
       "      <td>1689.01</td>\n",
       "      <td>1692.43</td>\n",
       "      <td>3681522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>174.28</td>\n",
       "      <td>175.15</td>\n",
       "      <td>172.89</td>\n",
       "      <td>174.97</td>\n",
       "      <td>25886167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>175.69</td>\n",
       "      <td>177.75</td>\n",
       "      <td>173.97</td>\n",
       "      <td>175.85</td>\n",
       "      <td>27436203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>175.94</td>\n",
       "      <td>176.00</td>\n",
       "      <td>174.54</td>\n",
       "      <td>175.53</td>\n",
       "      <td>19737419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>1124.90</td>\n",
       "      <td>1142.97</td>\n",
       "      <td>1124.75</td>\n",
       "      <td>1140.99</td>\n",
       "      <td>1450316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>1146.99</td>\n",
       "      <td>1158.28</td>\n",
       "      <td>1130.69</td>\n",
       "      <td>1147.80</td>\n",
       "      <td>1446047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>1150.06</td>\n",
       "      <td>1169.61</td>\n",
       "      <td>1146.19</td>\n",
       "      <td>1162.03</td>\n",
       "      <td>1443174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date     open     high      low    close    volume\n",
       "0   AMZN  2019-03-01  1655.13  1674.26  1651.00  1671.73   4974877\n",
       "1   AMZN  2019-03-04  1685.00  1709.43  1674.36  1696.17   6167358\n",
       "2   AMZN  2019-03-05  1702.95  1707.80  1689.01  1692.43   3681522\n",
       "3   AAPL  2019-03-01   174.28   175.15   172.89   174.97  25886167\n",
       "4   AAPL  2019-03-04   175.69   177.75   173.97   175.85  27436203\n",
       "5   AAPL  2019-03-05   175.94   176.00   174.54   175.53  19737419\n",
       "6   GOOG  2019-03-01  1124.90  1142.97  1124.75  1140.99   1450316\n",
       "7   GOOG  2019-03-04  1146.99  1158.28  1130.69  1147.80   1446047\n",
       "8   GOOG  2019-03-05  1150.06  1169.61  1146.19  1162.03   1443174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019-03-01</th>\n",
       "      <th>2019-03-04</th>\n",
       "      <th>2019-03-05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>25886167</td>\n",
       "      <td>27436203</td>\n",
       "      <td>19737419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>4974877</td>\n",
       "      <td>6167358</td>\n",
       "      <td>3681522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1450316</td>\n",
       "      <td>1446047</td>\n",
       "      <td>1443174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      2019-03-01  2019-03-04  2019-03-05\n",
       "AAPL    25886167    27436203    19737419\n",
       "AMZN     4974877     6167358     3681522\n",
       "GOOG     1450316     1446047     1443174"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-01', '2019-03-04', '2019-03-05', \n",
    "             '2019-03-01', '2019-03-04', '2019-03-05', \n",
    "             '2019-03-01', '2019-03-04', '2019-03-05'],\n",
    "    'open': [1655.13, 1685.0, 1702.95, 174.28, 175.69, 175.94, 1124.9, 1146.99, 1150.06], \n",
    "    'high': [1674.26, 1709.43, 1707.8, 175.15, 177.75, 176.0, 1142.97, 1158.28, 1169.61], \n",
    "    'low': [1651.0, 1674.36, 1689.01, 172.89, 173.97, 174.54, 1124.75, 1130.69, 1146.19], \n",
    "    'close': [1671.73, 1696.17, 1692.43, 174.97, 175.85, 175.53, 1140.99, 1147.8, 1162.03], \n",
    "    'volume': [4974877, 6167358, 3681522, 25886167, 27436203, 19737419, 1450316, 1446047, 1443174],\n",
    "    \n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    '2019-03-01': {'AAPL': 25886167, 'AMZN': 4974877, 'GOOG': 1450316},\n",
    "    '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    "    '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174}\n",
    "})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='symbol', columns='date', values='volume')\n",
      "Time to solution:  13.187 seconds\n",
      "Number of Programs Explored Till Now: 5918\n",
      "Total Number of Programs Explored: 27643\n",
      "Total Number of Programs Crashed: 0\n"
     ]
    }
   ],
   "source": [
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! That is quite a bit slow. If we wanted to build a synthesis service where people can get their input-output queries answered in real-time, this approach would definitely not work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a Generator\n",
    "\n",
    "In our brute-force synthesizer, we have been using a Depth-First enumeration strategy. The question we ask now is can devise a smart enumeration strategy that can make our generator return the most promising arguments first.\n",
    "\n",
    "Specifically, the enumeration order of argument combinations returned by `gen_pivot` is governed by the order of values returned by the individual operators (four `Select`s and one `OrderedSubset`). Therefore, to speed up our synthesizer, the operators need to return the correct values *first*.\n",
    "\n",
    "#### Can we train the individual operators to return values **smartly** i.e. adjust the order in which they return values based on the input-output example?\n",
    "##### For the purpose of the tutorial, let us focus on the first call to `Select` i.e. the operator that decides the value of the `columns` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Adding Input-Output Example as the Context\n",
    "\n",
    "In order to train the operator, we first need to provide access to the input-output example. Currently only `inp_df` is passed as an argument to the generator `gen_pivot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame, output_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns), context=(input_df, output_df),  # ADDING CONTEXT HERE\n",
    "                         uid=\"select_columns\") # Adding uid to aid identification while defining model\n",
    "    \n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in input_df.columns if i != arg_columns])\n",
    "    \n",
    "    # Whether to use a column or a list of columns\n",
    "    if Select([True, False]):\n",
    "        # Select one of the columns or None\n",
    "        arg_values = Select([None] + [i for i in input_df.columns if i not in {arg_columns, arg_index}])\n",
    "    else:\n",
    "        # Pick a Permutation/Ordered-Subset of the list of columns\n",
    "        arg_values = list(OrderedSubset([i for i in input_df.columns if i not in {arg_columns, arg_index}]))\n",
    "    \n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp, out):  # CHANGED : PASSING out AS AN ARGUMENT\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Tried: {num_explored}\")\n",
    "                \n",
    "                break  # CHANGED : Stop at first solution to avoid spending time exploring other programs\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Defining the Model\n",
    "\n",
    "Our model needs to take the list of columns (domain) passed to the `Select` operator, as well as the context and return a probabibility distribution over the list of columns.\n",
    "\n",
    "We are going to use a Graph-Neural-Network model for our Select operator. Covering this model is out-of-scope for this tutorial, but here are the key insights behind using this model.\n",
    "\n",
    "1. The transformation represented by an input-output example consisting of dataframes is a function of the relationships between the values in the input and the values in the output, rather the concrete values themselves.  For example, the concrete column names `Category`, `Expense` etc. are irrelevant. It is their position in the output dataframe that really captures the transformation.\n",
    "\n",
    "2. We can represent dataframes as a graph where each column, cell and index value is represented as a node, and edges represent relationships amongst these nodes. The nodes are labeled with the type of the value (int, str etc.) rather than the value itself. For example, each column node will have a `COLUMN` edge to all the cell nodes in the corresponding column. We will also have an `EQUALITY` edge between between each pair of nodes that have the same concrete value.\n",
    "\n",
    "Here is a graphical representation of the graph encoding for the given input and output dataframe along with the domain for the `Select` operator we're trying to learn a model for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/input-output-example.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>\n",
    "<img src=\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/imgs/graph-encoding-example.png\" alt=\"Pivot Documentation\" style=\"width: 80%;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the model for the generator. For more details, refer to the `models.py` file in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atlas.models.imitation import IndependentOperatorsModel\n",
    "from atlas.operators import operator\n",
    "from models import PivotSelectModel\n",
    "\n",
    "class PivotGeneratorModel(IndependentOperatorsModel):\n",
    "    @operator(name='Select', uid=\"select_columns\")\n",
    "    def SelectColumns(*args, **kwargs):\n",
    "        config = {\n",
    "            'learning_rate': 0.01,\n",
    "            'node_dimension': 50,\n",
    "            'classifier_hidden_dims': [50],\n",
    "            'batch_size': 30000,  # number of nodes in a batch\n",
    "            'layer_timesteps': [1, 1, 1]\n",
    "        }\n",
    "\n",
    "        return PivotSelectModel(config, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training Data\n",
    "\n",
    "Training data for our purposes consists of **traces** of generator executions that produce the correct program given an input-output example. These traces store the correct choices made by the operators and hence are suffice as training data for the operators.\n",
    "\n",
    "This data has been generated randomly. In particular, we collect random input dataframes run them through our brute-force generator, randomly pick some argument combinations and execute it to get the output. This gives us a `(input, output, program)` tuple that suffices as training data. For more details, refer to `data_generation.py`.\n",
    "\n",
    "**NOTE:** This is only for illustration purposes, so you should not worry too much about understanding the format of these traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        GeneratorTrace(inputs=((      0           1     2       3                 4   5\n",
       "0   baz       123.4   baz  Joseph      banana_foo_2  50\n",
       "1   bar  23894243.7  fizz     Amy       date_bar_24  30\n",
       "2  buzz       123.4  buzz    Anne  cherimoya_baz_71  20\n",
       "3   foo       123.4  buzz  Nikita      apple_fizz_7  35,                             1                          2                      \\\n",
       "3                         Amy   Anne Joseph Nikita   Amy  Anne Joseph Nikita   \n",
       "4                                                                              \n",
       "apple_fizz_7              NaN    NaN    NaN  123.4   NaN   NaN    NaN   buzz   \n",
       "banana_foo_2              NaN    NaN  123.4    NaN   NaN   NaN    baz    NaN   \n",
       "cherimoya_baz_71          NaN  123.4    NaN    NaN   NaN  buzz    NaN    NaN   \n",
       "date_bar_24       2.38942e+07    NaN    NaN    NaN  fizz   NaN    NaN    NaN   \n",
       "\n",
       "                    5                     \n",
       "3                 Amy Anne Joseph Nikita  \n",
       "4                                         \n",
       "apple_fizz_7      NaN  NaN    NaN     35  \n",
       "banana_foo_2      NaN  NaN     50    NaN  \n",
       "cherimoya_baz_71  NaN   20    NaN    NaN  \n",
       "date_bar_24        30  NaN    NaN    NaN  ), {}),\n",
       "                       op_traces=[\n",
       "        OpTrace(op_info=OpInfo(sid='/gen_pivot_args/Select@select_columns@1', gen_name='gen_pivot_args', op_type='Select', index=1, gen_group=None, uid='select_columns', tags=None),\n",
       "                choice=3,\n",
       "                domain=[0, 1, 2, 3, 4, 5],\n",
       "                context=(      0           1     2       3                 4   5\n",
       "0   baz       123.4   baz  Joseph      banana_foo_2  50\n",
       "1   bar  23894243.7  fizz     Amy       date_bar_24  30\n",
       "2  buzz       123.4  buzz    Anne  cherimoya_baz_71  20\n",
       "3   foo       123.4  buzz  Nikita      apple_fizz_7  35,                             1                          2                      \\\n",
       "3                         Amy   Anne Joseph Nikita   Amy  Anne Joseph Nikita   \n",
       "4                                                                              \n",
       "apple_fizz_7              NaN    NaN    NaN  123.4   NaN   NaN    NaN   buzz   \n",
       "banana_foo_2              NaN    NaN  123.4    NaN   NaN   NaN    baz    NaN   \n",
       "cherimoya_baz_71          NaN  123.4    NaN    NaN   NaN  buzz    NaN    NaN   \n",
       "date_bar_24       2.38942e+07    NaN    NaN    NaN  fizz   NaN    NaN    NaN   \n",
       "\n",
       "                    5                     \n",
       "3                 Amy Anne Joseph Nikita  \n",
       "4                                         \n",
       "apple_fizz_7      NaN  NaN    NaN     35  \n",
       "banana_foo_2      NaN  NaN     50    NaN  \n",
       "cherimoya_baz_71  NaN   20    NaN    NaN  \n",
       "date_bar_24        30  NaN    NaN    NaN  ),\n",
       "                **{}\n",
       "               ), \n",
       "OpTrace(op_info=OpInfo(sid='/gen_pivot_args/Select@@1', gen_name='gen_pivot_args', op_type='Select', index=1, gen_group=None, uid=None, tags=None),\n",
       "        choice=4,\n",
       "        domain=[None, 0, 1, 2, 4, 5],\n",
       "        context=None,\n",
       "        **{}\n",
       "       ), \n",
       "OpTrace(op_info=OpInfo(sid='/gen_pivot_args/Select@@2', gen_name='gen_pivot_args', op_type='Select', index=2, gen_group=None, uid=None, tags=None),\n",
       "        choice=False,\n",
       "        domain=[True, False],\n",
       "        context=None,\n",
       "        **{}\n",
       "       ), \n",
       "OpTrace(op_info=OpInfo(sid='/gen_pivot_args/OrderedSubset@@1', gen_name='gen_pivot_args', op_type='OrderedSubset', index=1, gen_group=None, uid=None, tags=None),\n",
       "        choice=(1, 2, 5),\n",
       "        domain=[0, 1, 2, 5],\n",
       "        context=None,\n",
       "        **{}\n",
       "       )]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "from urllib.request import urlopen\n",
    "\n",
    "data = pickle.load(urlopen(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/training_data_pivot_columns.pkl\"))\n",
    "data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 2234.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2166.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Training model for OpInfo(sid='/gen_pivot_args/Select@select_columns@1', gen_name='gen_pivot_args', op_type='Select', index=1, gen_group=None, uid='select_columns', tags=None)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:317: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training(1/30)] Loss:  1.433152 Accuracy:  0.4720\n",
      "[Validation(1/30)] Loss:  1.241686 Accuracy:  0.3800\n",
      "[Training(2/30)] Loss:  1.322016 Accuracy:  0.4580\n",
      "[Validation(2/30)] Loss:  1.044748 Accuracy:  0.3300\n",
      "[Training(3/30)] Loss:  1.124238 Accuracy:  0.4480\n",
      "[Validation(3/30)] Loss:  1.082418 Accuracy:  0.3500\n",
      "[Training(4/30)] Loss:  1.123267 Accuracy:  0.4680\n",
      "[Validation(4/30)] Loss:  1.071257 Accuracy:  0.3900\n",
      "[Training(5/30)] Loss:  1.102100 Accuracy:  0.4720\n",
      "[Validation(5/30)] Loss:  1.030015 Accuracy:  0.3900\n",
      "[Training(6/30)] Loss:  1.062197 Accuracy:  0.4760\n",
      "[Validation(6/30)] Loss:  1.004234 Accuracy:  0.3900\n",
      "[Training(7/30)] Loss:  1.043536 Accuracy:  0.4800\n",
      "[Validation(7/30)] Loss:  0.992720 Accuracy:  0.3800\n",
      "[Training(8/30)] Loss:  1.030523 Accuracy:  0.4980\n",
      "[Validation(8/30)] Loss:  0.992106 Accuracy:  0.4000\n",
      "[Training(9/30)] Loss:  1.018177 Accuracy:  0.5020\n",
      "[Validation(9/30)] Loss:  0.987970 Accuracy:  0.4100\n",
      "[Training(10/30)] Loss:  1.005545 Accuracy:  0.5040\n",
      "[Validation(10/30)] Loss:  0.991990 Accuracy:  0.3900\n",
      "[Training(11/30)] Loss:  1.001968 Accuracy:  0.5060\n",
      "[Validation(11/30)] Loss:  1.000968 Accuracy:  0.4300\n",
      "[Training(12/30)] Loss:  0.998323 Accuracy:  0.5140\n",
      "[Validation(12/30)] Loss:  1.010648 Accuracy:  0.4300\n",
      "[Training(13/30)] Loss:  0.993639 Accuracy:  0.5300\n",
      "[Validation(13/30)] Loss:  1.024362 Accuracy:  0.4500\n",
      "[Training(14/30)] Loss:  0.987042 Accuracy:  0.5280\n",
      "[Validation(14/30)] Loss:  1.037082 Accuracy:  0.4700\n",
      "[Training(15/30)] Loss:  0.983957 Accuracy:  0.5440\n",
      "[Validation(15/30)] Loss:  1.012237 Accuracy:  0.4900\n",
      "[Training(16/30)] Loss:  0.963646 Accuracy:  0.5460\n",
      "[Validation(16/30)] Loss:  0.965060 Accuracy:  0.5100\n",
      "[Training(17/30)] Loss:  0.933991 Accuracy:  0.5600\n",
      "[Validation(17/30)] Loss:  0.936409 Accuracy:  0.5500\n",
      "[Training(18/30)] Loss:  0.917178 Accuracy:  0.5960\n",
      "[Validation(18/30)] Loss:  0.905520 Accuracy:  0.6000\n",
      "[Training(19/30)] Loss:  0.884501 Accuracy:  0.6220\n",
      "[Validation(19/30)] Loss:  0.875327 Accuracy:  0.6200\n",
      "[Training(20/30)] Loss:  0.846751 Accuracy:  0.6400\n",
      "[Validation(20/30)] Loss:  0.856619 Accuracy:  0.6300\n",
      "[Training(21/30)] Loss:  0.765619 Accuracy:  0.6680\n",
      "[Validation(21/30)] Loss:  0.826058 Accuracy:  0.6300\n",
      "[Training(22/30)] Loss:  0.687136 Accuracy:  0.7000\n",
      "[Validation(22/30)] Loss:  0.668685 Accuracy:  0.7000\n",
      "[Training(23/30)] Loss:  0.619863 Accuracy:  0.7260\n",
      "[Validation(23/30)] Loss:  0.633214 Accuracy:  0.7000\n",
      "[Training(24/30)] Loss:  0.530062 Accuracy:  0.7800\n",
      "[Validation(24/30)] Loss:  0.597910 Accuracy:  0.7200\n",
      "[Training(25/30)] Loss:  0.542301 Accuracy:  0.8000\n",
      "[Validation(25/30)] Loss:  0.461273 Accuracy:  0.8400\n",
      "[Training(26/30)] Loss:  0.427874 Accuracy:  0.8480\n",
      "[Validation(26/30)] Loss:  0.396331 Accuracy:  0.8600\n",
      "[Training(27/30)] Loss:  0.344740 Accuracy:  0.8920\n",
      "[Validation(27/30)] Loss:  0.249228 Accuracy:  0.8900\n",
      "[Training(28/30)] Loss:  0.242910 Accuracy:  0.9180\n",
      "[Validation(28/30)] Loss:  0.183535 Accuracy:  0.9300\n",
      "[Training(29/30)] Loss:  0.191365 Accuracy:  0.9360\n",
      "[Validation(29/30)] Loss:  0.154798 Accuracy:  0.9400\n",
      "[Training(30/30)] Loss:  0.117142 Accuracy:  0.9580\n",
      "[Validation(30/30)] Loss:  0.113996 Accuracy:  0.9600\n",
      "Restoring model with accuracy 0.9599999785423279 and loss 0.11399572342634201\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmpw3svr_14/model.weights\n"
     ]
    }
   ],
   "source": [
    "model = PivotGeneratorModel()\n",
    "train = data[:500]\n",
    "valid = data[500:]\n",
    "model.train(train, valid, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_pivot(inp, out):\n",
    "    start_time = time.time()\n",
    "    num_explored = 0\n",
    "    num_errors = 0\n",
    "    for args in gen_pivot_args.generate(inp, out).with_model(model):  # CHANGED : Using model\n",
    "        num_explored += 1\n",
    "        \n",
    "        try:\n",
    "            # If there are exceptions while running pivot or checking, skip\n",
    "            result = inp.pivot(**args)\n",
    "            if check_equal(result, out):\n",
    "                print(\"Found Solution!\", \n",
    "                      f\"inp.pivot(index='{args['index']}', columns='{args['columns']}', values='{args['values']}')\")\n",
    "                print(f\"Time to solution: {time.time() - start_time: .3f} seconds\")\n",
    "                print(f\"Number of Programs Tried: {num_explored}\")\n",
    "                \n",
    "                break\n",
    "\n",
    "        except Exception as e:\n",
    "            num_errors += 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for operator /gen_pivot_args/Select@select_columns@1\n",
      "[('date', 0.9620377), ('volume', 0.037817474), ('symbol', 0.00012981212), ('high', 5.758068e-06), ('low', 5.758068e-06), ('open', 2.6130274e-06), ('close', 7.516266e-07)]\n",
      "Found Solution! inp.pivot(index='symbol', columns='date', values='volume')\n",
      "Time to solution:  4.943 seconds\n",
      "Number of Programs Tried: 1969\n"
     ]
    }
   ],
   "source": [
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! The model for the first `Select` helped it pick the right value in the first try (and with >95% confidence) which significantly improved the search time. Why stop at using a model for only one `Select`. We can use models for all the operators!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Defining a Model for All Operators\n",
    "\n",
    "First let's give the same context to all the operators and not just the first `Select`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@generator\n",
    "def gen_pivot_args(input_df: pd.DataFrame, output_df: pd.DataFrame):\n",
    "    # Select one of columns\n",
    "    arg_columns = Select(list(input_df.columns), context=(input_df, output_df))\n",
    "    # Select one of columns or None\n",
    "    arg_index = Select([None] + [i for i in list(input_df.columns) if i != arg_columns], context=(input_df, output_df))\n",
    "\n",
    "    # Select one of columns or list of columns\n",
    "    if Select([True, False], context=(input_df, output_df), uid=\"branch\"):\n",
    "        arg_values = Select([None] + [i for i in list(input_df.columns) if i != arg_columns and i != arg_index],\n",
    "                            context=(input_df, output_df))\n",
    "    else:\n",
    "        arg_values = list(OrderedSubset([i for i in list(input_df.columns) if i != arg_columns and i != arg_index],\n",
    "                                        context=(input_df, output_df)))\n",
    "\n",
    "    return {'index': arg_index, 'columns': arg_columns, 'values': arg_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the model as before, covering all the operators this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_config = {\n",
    "    'learning_rate': 0.01,\n",
    "    'node_dimension': 50,\n",
    "    'classifier_hidden_dims': [50],\n",
    "    'batch_size': 30000,\n",
    "    'layer_timesteps': [1, 1, 1]\n",
    "}\n",
    "\n",
    "class PivotGeneratorModel(IndependentOperatorsModel):\n",
    "    @operator\n",
    "    def Select(*args, **kwargs):\n",
    "        return PivotSelectModel(common_config)\n",
    "\n",
    "    @operator(name='Select', uid=\"branch\")\n",
    "    def SelectBranch(*args, **kwargs):\n",
    "        return PivotClassifyModel(common_config, domain_size=2)\n",
    "\n",
    "    @operator\n",
    "    def OrderedSubset(*args, **kwargs):\n",
    "        return PivotOrderedSubsetModel(common_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can train the model using the following commands.\n",
    "\n",
    "```python\n",
    "model = PivotGeneratorModel()\n",
    "data = pickle.load(urlopen(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/training_data_pivot_full.pkl\"))\n",
    "train_data = data[:500]\n",
    "valid_data = data[500:]\n",
    "model.train(train_data, valid_data, num_epochs=100)\n",
    "```\n",
    "\n",
    "Since training for 100 epochs would take some time, we'll load a pre-trained model (obtained through the same set of commands)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmph301q2dz/models/gen_pivot_args/Select@@1/model.weights\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmph301q2dz/models/gen_pivot_args/Select@@2/model.weights\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmph301q2dz/models/gen_pivot_args/Select@branch@1/model.weights\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmph301q2dz/models/gen_pivot_args/Select@@3/model.weights\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/s9/__w2d9dx2ljdx9qk865hh5qs559bh9/T/tmph301q2dz/models/gen_pivot_args/OrderedSubset@@1/model.weights\n"
     ]
    }
   ],
   "source": [
    "from atlas.models.utils import restore_model\n",
    "model = restore_model(\"https://risecamp2019-atlas.s3.us-east-2.amazonaws.com/pandas-pivot-model-full.zip\", from_url=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='symbol', columns='date', values='volume')\n",
      "Time to solution:  0.044 seconds\n",
      "Number of Programs Tried: 1\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-01', '2019-03-04', '2019-03-05', \n",
    "             '2019-03-01', '2019-03-04', '2019-03-05', \n",
    "             '2019-03-01', '2019-03-04', '2019-03-05'],\n",
    "    'open': [1655.13, 1685.0, 1702.95, 174.28, 175.69, 175.94, 1124.9, 1146.99, 1150.06], \n",
    "    'high': [1674.26, 1709.43, 1707.8, 175.15, 177.75, 176.0, 1142.97, 1158.28, 1169.61], \n",
    "    'low': [1651.0, 1674.36, 1689.01, 172.89, 173.97, 174.54, 1124.75, 1130.69, 1146.19], \n",
    "    'close': [1671.73, 1696.17, 1692.43, 174.97, 175.85, 175.53, 1140.99, 1147.8, 1162.03], \n",
    "    'volume': [4974877, 6167358, 3681522, 25886167, 27436203, 19737419, 1450316, 1446047, 1443174],\n",
    "    \n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    '2019-03-01': {'AAPL': 25886167, 'AMZN': 4974877, 'GOOG': 1450316},\n",
    "    '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    "    '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='symbol', columns='date', values='volume')\n",
      "Time to solution:  0.034 seconds\n",
      "Number of Programs Tried: 1\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'symbol': ['AMZN', 'AMZN', 'AMZN', 'AAPL', 'AAPL', 'AAPL', 'GOOG', 'GOOG', 'GOOG'],\n",
    "    'date': ['2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06', \n",
    "             '2019-03-04', '2019-03-05', '2019-03-06'],\n",
    "    'volume': [6167358, 3681522, 3996001, 27436203, 19737419, 20810384, 1446047, 1443174, 1099289]\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    " '2019-03-04': {'AAPL': 27436203, 'AMZN': 6167358, 'GOOG': 1446047},\n",
    " '2019-03-05': {'AAPL': 19737419, 'AMZN': 3681522, 'GOOG': 1443174},\n",
    " '2019-03-06': {'AAPL': 20810384, 'AMZN': 3996001, 'GOOG': 1099289}\n",
    "})\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our synthesizer gets it right on the first try on both occasions! Here are some more examples involving different dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>foo</th>\n",
       "      <th>bar</th>\n",
       "      <th>baz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>C</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two</td>\n",
       "      <td>A</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two</td>\n",
       "      <td>B</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>two</td>\n",
       "      <td>C</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   foo bar  baz\n",
       "0  one   A   10\n",
       "1  one   B   20\n",
       "2  one   C   30\n",
       "3  two   A   40\n",
       "4  two   B   50\n",
       "5  two   C   60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A   B   C\n",
       "one  10  20  30\n",
       "two  40  50  60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='foo', columns='bar', values='baz')\n",
      "Time to solution:  0.028 seconds\n",
      "Number of Programs Tried: 1\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "  'foo': ['one', 'one', 'one', 'two', 'two', 'two'],\n",
    "  'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "  'baz': [10, 20, 30, 40, 50, 60],\n",
    "})\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    'A': {'one': 10, 'two': 40},\n",
    "    'B': {'one': 20, 'two': 50},\n",
    "    'C': {'one': 30, 'two': 60}\n",
    "})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Added By</th>\n",
       "      <th>Expense</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>Terrace</td>\n",
       "      <td>9971.66</td>\n",
       "      <td>Theresa</td>\n",
       "      <td>98.34</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-18</td>\n",
       "      <td>Pox</td>\n",
       "      <td>9726.03</td>\n",
       "      <td>Margaret</td>\n",
       "      <td>245.63</td>\n",
       "      <td>Lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Gate 320</td>\n",
       "      <td>9604.14</td>\n",
       "      <td>Helena</td>\n",
       "      <td>121.89</td>\n",
       "      <td>Social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-24</td>\n",
       "      <td>Pox</td>\n",
       "      <td>9356.04</td>\n",
       "      <td>Katherine</td>\n",
       "      <td>248.00</td>\n",
       "      <td>Lunch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Location  Balance   Added By  Expense Category\n",
       "0  2018-02-18   Terrace  9971.66    Theresa    98.34   Social\n",
       "1  2018-02-18       Pox  9726.03   Margaret   245.63    Lunch\n",
       "2  2018-02-24  Gate 320  9604.14     Helena   121.89   Social\n",
       "3  2018-02-24       Pox  9356.04  Katherine   248.00    Lunch"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lunch</th>\n",
       "      <th>Social</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-18</th>\n",
       "      <td>245.63</td>\n",
       "      <td>98.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-24</th>\n",
       "      <td>248.00</td>\n",
       "      <td>121.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lunch  Social\n",
       "2018-02-18  245.63   98.34\n",
       "2018-02-24  248.00  121.89"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Solution! inp.pivot(index='Date', columns='Category', values='Expense')\n",
      "Time to solution:  0.029 seconds\n",
      "Number of Programs Tried: 1\n"
     ]
    }
   ],
   "source": [
    "inp_df = pd.DataFrame({\n",
    "    'Date': {0: '2018-02-18', 1: '2018-02-18', 2: '2018-02-24', 3: '2018-02-24'},\n",
    "    'Location': {0: 'Terrace', 1: 'Pox', 2: 'Gate 320', 3: 'Pox'},\n",
    "    'Balance': {0: 9971.66, 1: 9726.03, 2: 9604.14, 3: 9356.04},\n",
    "    'Added By': {0: 'Theresa', 1: 'Margaret', 2: 'Helena', 3:'Katherine'},\n",
    "    'Expense': {0: 98.34, 1: 245.63, 2: 121.89, 3: 248.0},\n",
    "    'Category': {0: 'Social', 1: 'Lunch', 2: 'Social', 3: 'Lunch'}})\n",
    "\n",
    "out_df = pd.DataFrame({'Lunch': {'2018-02-18': 245.63, '2018-02-24': 248.0},\n",
    " 'Social': {'2018-02-18': 98.34, '2018-02-24': 121.89}})\n",
    "\n",
    "print(\"Input DataFrame\")\n",
    "display(inp_df)\n",
    "print(\"Output DataFrame\")\n",
    "display(out_df)\n",
    "\n",
    "synthesize_pivot(inp_df, out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've learnt to express a search space using generators in Atlas. A Generator is a regular Python function which uses some special operators to capture non-deterministic decisions (such as selecting one element from a list). We built a generator for the `pivot` function in Pandas which helped us construct a synthesizer, which works fine for small inputs but suffers on large ones as the search space is too large. We then used graph-based neural-network models to *guide* the generator towards programs in the search space that are most likely to produce the output given the input. In fact, our learned synthesizer gets the correct program on the first try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
