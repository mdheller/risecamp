{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Party XGBoost on Single Party Data\n",
    "First we'll train an XGBoost model on only your data. Here, a party will only have a subset of the data that's globally available. Therefore, we would expect the trained model to not be as robust as a model trained on all available data. We'll look at the performance of a XGBoost model that's trained on only your data. \n",
    "![title](img/exercise1.png)\n",
    "\n",
    "Note that this notebook is the same for aggregators and non-aggregators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in and examine the comma separated training data partition belonging to your party to get a better understanding of the data. As the aggregator, your `party_id` is 1.\n",
    "* Training data for the Higgs boson dataset is at `/data/hb/hb_train_{party_id}.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the comma separated training data using the pandas.read_csv() function \n",
    "# and print out the first few rows of the dataset using the .head() function\n",
    "training_data_path = \"/data/hb/hb_train_1.csv\"\n",
    "\n",
    "training_data = pd.read_csv(training_data_path, sep=\",\", header=None)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into labels and features\n",
    "y_train = training_data.iloc[:, 0]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train = training_data.iloc[:, 1:]\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the test data.\n",
    "* Test data for the Higgs boson dataset is located at `/data/hb/hb_test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test data into labels and features\n",
    "test_data_path = \"/data/hb/hb_test.csv\"\n",
    "test_data = pd.read_csv(test_data_path, sep=\",\", header=None)\n",
    "y_test = test_data.iloc[:, 0]\n",
    "x_test = test_data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Evaluation\n",
    "Train the model with the training data. Feel free to play with the hyperparameters. For example, you may want to adjust the `n_estimators` hyperparameter, which adjusts the number of trees in the ensemble. For a full list of hyperparameters, go here: https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier()\n",
    "print(\"Beginning training...\")\n",
    "\n",
    "# TODO: Train a classifier using the model.fit(features, labels) function\n",
    "# ...\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions and evaluate the model with the test data. Feel free to use different error functions. We suggest the sklearn `accuracy_score()` function for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use the model to get predictions for the test set and calculate the prediction error\n",
    "# Use the model.predict(x_test) function\n",
    "preds = # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of the predictions\n",
    "accuracy_percent = str(accuracy_score(y_test, preds) * 100)[:5] + \"%\"\n",
    "print(\"Your model achieved %s accuracy \" % accuracy_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare your locally trained model's accuracy with those of other members of your federation. How do you think your locally trained model will perform on data that doesn't fit the distribution of your training data?\n",
    "\n",
    "Once you've finished discussing, let's move to [Exercise 2](exercise2-aggregator.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
